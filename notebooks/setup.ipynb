{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d741b5ff-4692-484d-8fc8-9601b337f299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b1deb-86f1-411a-a909-9a5473e03938",
   "metadata": {},
   "source": [
    "#### Create the ChromaDB Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff381ee-d939-4dc2-a3fa-4db5c441c5de",
   "metadata": {},
   "source": [
    "We structure our data as follows:\n",
    "\n",
    "```bash\n",
    "data/\n",
    "|__ chromadb/ # This is where chromadb stores our data\n",
    "|__ {BACKEND_DATA_SOURCE_PATH}.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48f0a9c5-ef2d-4d96-9e57-f5d192d7a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that this is the same as the lines contained in docker-compose.yaml\n",
    "BACKEND_CHROMADB_PATH=\"./data/chromadb\"\n",
    "BACKEND_CHROMADB_COLLECTION_NAME=\"np2024-dataset-test\"\n",
    "BACKEND_DATA_SOURCE_PATH=\"./data/202407251532-pandas-cleaned.csv\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=BACKEND_CHROMADB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a44d3d-aeba-4810-a4c2-da736d8e0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(\n",
    "    name = BACKEND_CHROMADB_COLLECTION_NAME, \n",
    "    # embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"Huffon/sentence-klue-roberta-base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a12936e-0c30-43d1-97c8-a9615d614655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['np2024-dataset', 'np2024-dataset-test']\n"
     ]
    }
   ],
   "source": [
    "# Check that the collection has been successfully created\n",
    "print([entry.name for entry in chroma_client.list_collections()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0608833-7086-4503-abfd-faa8332f0975",
   "metadata": {},
   "source": [
    "#### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ddca75-9fff-46b8-8af1-397458daa1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv(BACKEND_DATA_SOURCE_PATH).dropna(subset = ['body'])\n",
    "\n",
    "columns = ['url', 'repository_url', 'id', 'user', 'node_id', 'title', 'state', 'labels', 'created_at', 'updated_at', 'body']\n",
    "\n",
    "# Node ID: Assigned unique uuid\n",
    "# Title: Name or Short Description of the defect\n",
    "# State: Whether the defect is still open or closed\n",
    "# URL: The url to whichever relevant link on more details of the defect\n",
    "# Body: Description of the defect\n",
    "# Create At: Date the defect is created\n",
    "\n",
    "required_columns = [\"node_id\", \"title\", \"state\", \"url\", \"body\", \"created_at\"]\n",
    "df_columns = df.columns\n",
    "\n",
    "if \"node_id\" not in df_columns:\n",
    "    print(f\"node_id not found, creating default uuid4 column.\")\n",
    "    df[\"node_id\"] = str(uuid.uuid4().hex)\n",
    "if \"state\" not in df_columns:\n",
    "    print(f\"state not found, creating default state column as open.\")\n",
    "    df[\"state\"] = \"open\"\n",
    "if \"url\" not in df_columns:\n",
    "    print(f\"url not found, creating default state column as null.\")\n",
    "    df[\"url\"] = None\n",
    "if \"created_at\" not in df_columns:\n",
    "    print(f\"created_at not found, creating default state column as today.\")\n",
    "    df[\"url\"] = datetime.today()\n",
    "    \n",
    "if \"title\" not in df_columns or \"body\" not in df_columns:\n",
    "    raise ValueError(f\"title or body not found in df.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb24f7e-fb5a-4ccf-bba8-e7378a29606c",
   "metadata": {},
   "source": [
    "#### Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01c9e3d2-c5e8-40b1-95c7-9b3e97a2306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str):\n",
    "    ## Change this text cleaning to that specific to your dataset\n",
    "    pattern = re.compile(r'### Pandas version checks.*?### Reproducible Example', re.DOTALL)\n",
    "    # Replace the matched section with '### Reproducible Example'\n",
    "    cleaned_text = re.sub(pattern, '### Reproducible Example', text)\n",
    "    # Regex to match the ### Installed Versions section and its content\n",
    "    pattern = re.compile(r'### Installed Versions.*?(</details>|$)', re.DOTALL)\n",
    "    # Replace the matched section with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip().lower().replace(\"###\", \"\")\n",
    "    cleaned_text = re.sub(r'\\n\\s*\\n+', ' ', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c868a30-8626-49ef-81a3-c08b61f00c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_body'] = df['body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867262e-8786-4482-9d93-fe067e680bdd",
   "metadata": {},
   "source": [
    "#### Create the dataset on ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a28883d5-4963-4bc0-b8cb-56b8103fafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from tqdm import tqdm\n",
    "\n",
    "i, chunk_size = 0, 1_000\n",
    "\n",
    "for row in df.itertuples():\n",
    "    # Insert the embedded sentences into the database on every chunk_size chunk\n",
    "    if i % chunk_size == 0 and i != 0:        \n",
    "        chunk_df = df.iloc[i - chunk_size: i]\n",
    "        collection.upsert(\n",
    "            documents = chunk_df[\"cleaned_body\"].to_list(), \n",
    "            ids = chunk_df[\"node_id\"].to_list()\n",
    "        )\n",
    "    i += 1\n",
    "    \n",
    "collection.upsert(\n",
    "    documents = df.iloc[i - chunk_size:]['cleaned_body'].to_list(), \n",
    "    ids = df.iloc[i - chunk_size:][\"node_id\"].to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845dace-8229-4610-b68e-f4391e9dce20",
   "metadata": {},
   "source": [
    "#### Test the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d9d1c3f-a951-4c7f-92a2-037c639c1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"pd.ExcelWriter cannot accept an io.BytesIO instance as first arg\"\n",
    "results = collection.query(query_texts=[query], n_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a53aeb9-580f-4b47-9c12-828e049067c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['I_kwDOAA0YD86G8bmy',\n",
       "   'MDExOlB1bGxSZXF1ZXN0Mzc5MDc2NzM=',\n",
       "   'MDU6SXNzdWU4MjQwMDA1MzE=',\n",
       "   'I_kwDOAA0YD85C6Y-i',\n",
       "   'MDU6SXNzdWU5NzMwNDg0MTE=',\n",
       "   'MDU6SXNzdWUzMDc5NDg3NQ==',\n",
       "   'I_kwDOAA0YD850NvPV',\n",
       "   'I_kwDOAA0YD85gj_j2',\n",
       "   'I_kwDOAA0YD85ATo1u',\n",
       "   'MDExOlB1bGxSZXF1ZXN0MjY2NzM0Mjc=']],\n",
       " 'distances': [[0.6897023916244507,\n",
       "   0.8048410415649414,\n",
       "   0.8124653100967407,\n",
       "   0.829188346862793,\n",
       "   0.8643962740898132,\n",
       "   0.8813604116439819,\n",
       "   0.8921693563461304,\n",
       "   0.9173852205276489,\n",
       "   0.9438368082046509,\n",
       "   0.9569565653800964]],\n",
       " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[' reproducible example ```python\\nimport pandas as pd\\r excel_data = io.bytesio()\\r\\nwith pd.excelwriter(excel_data, engine=\"openpyxl\", mode=\"w\") as writer:\\r\\n    pd.dataframe({\"a\": [1, 2], \"b\": [3, 4]}).to_excel(writer, sheet_name=\"example\", index=false)\\n```  issue description the code above writes a dataframe in an excelfile directly in memory, in a io.bytesio. the code actually works and does what it\\'s expected to do, however the typing fails.\\r this is because the first argument of `pd.dataframe` expects `path: filepath | writeexcelbuffer | excelwriter`, however\\r\\nthe `truncate` function\\'s signature differs in `writeexcelbuffer` and `io.bytesio`:\\r\\n```diff\\r\\n- def truncate(self, size: int | none = ...) -> int:\\r\\n+ def truncate(self, size: int | none = ..., /) -> int:\\r\\n```  expected behavior this should pass type checks in `mypy` or `pylance`.',\n",
       "   'add support for stringio/bytesio to excelwriter\\nadd vbench support for writing excel files\\nadd support for serializing lists/dicts to strings\\nfix bug when reading blank excel sheets closes #8188\\ncloses #7074\\ncloses #6403\\ncloses #7171',\n",
       "   '- [x] i have checked that this issue has not already been reported.\\r - [x] i have confirmed this bug exists on the latest version of pandas.\\r - [x] (optional) i have confirmed this bug exists on the master branch of pandas.\\r ---\\r # code sample, a copy-pastable example\\r ```python\\r\\nimport pandas as pd\\r\\nimport io\\r df = pd.dataframe({\"a\": [0, 1], \"b\": [10, 11]})\\r for engine in [\"openpyxl\", \"xlsxwriter\", \"odf\"]:\\r\\n    excel = io.bytesio()\\r\\n    with pd.excelwriter(excel, engine=engine) as writer:\\r\\n        df.to_excel(writer, sheet_name=\"foo\", columns=[\"a\"], index=false)\\r\\n        df.to_excel(writer, sheet_name=\"foo\", columns=[\"b\"], startcol=1, index=false)\\r     result = pd.read_excel(excel, \"foo\")\\r\\n    print(engine)\\r\\n    print(result)\\r\\n    print()\\r\\n```\\r produces:\\r\\n```\\r\\nopenpyxl\\r\\n   a   b\\r\\n0  0  10\\r\\n1  1  11\\r xlsxwriter\\r\\n   a   b\\r\\n0  0  10\\r\\n1  1  11\\r odf\\r\\n     a unnamed: 1\\r\\n0  0.0        nan\\r\\n1  1.0        nan\\r\\n2  nan          b\\r\\n3  nan         10\\r\\n4  nan         11\\r\\n```\\r adding this test to `test_writers.py` (line 1327) will also catch the issue:\\r\\n```python\\r     def test_excel_multiple_writes_one_writer(self, path):\\r\\n        df = dataframe({\"a\": [0, 1], \"b\": [10, 11]})\\r         with excelwriter(path) as writer:\\r\\n            df.to_excel(writer, columns=[\"a\"], index=false)\\r\\n            df.to_excel(writer, columns=[\"b\"], startcol=1, index=false)\\r         result = pd.read_excel(path)\\r\\n        tm.assert_frame_equal(result, df)\\r\\n```\\r # problem description\\r\\nthis came up when implementing #40231, the behaviour between the engines here seems to be inconsistent.\\r # output of ``pd.show_versions()``\\r <details>\\r installed versions\\r\\n------------------\\r\\ncommit           : 6baec67643923ae93b685bdec01105b51f1c0a94\\r\\npython           : 3.7.3.final.0\\r\\npython-bits      : 64\\r\\nos               : windows\\r\\nos-release       : 10\\r\\nversion          : 10.0.19041\\r\\nmachine          : amd64\\r\\nprocessor        : intel64 family 6 model 60 stepping 3, genuineintel\\r\\nbyteorder        : little\\r\\nlc_all           : none\\r\\nlang             : en_us.utf-8\\r\\nlocale           : none.none\\r pandas           : 1.3.0.dev0+979.g6baec67643.dirty\\r\\nnumpy            : 1.20.0\\r\\npytz             : 2019.1\\r\\ndateutil         : 2.8.1\\r\\npip              : 20.3.3\\r\\nsetuptools       : 41.4.0\\r\\ncython           : 0.29.21\\r\\npytest           : 6.2.2\\r\\nhypothesis       : 6.1.1\\r\\nsphinx           : 2.4.0\\r\\nblosc            : none\\r\\nfeather          : 0.4.0\\r\\nxlsxwriter       : 1.3.7\\r\\nlxml.etree       : 4.4.1\\r\\nhtml5lib         : none\\r\\npymysql          : none\\r\\npsycopg2         : none\\r\\njinja2           : 2.10.1\\r\\nipython          : 7.5.0\\r\\npandas_datareader: none\\r\\nbs4              : 4.8.0\\r\\nbottleneck       : none\\r\\nfsspec           : none\\r\\nfastparquet      : none\\r\\ngcsfs            : none\\r\\nmatplotlib       : 3.1.0\\r\\nnumexpr          : 2.7.1\\r\\nodfpy            : none\\r\\nopenpyxl         : 3.0.6\\r\\npandas_gbq       : none\\r\\npyarrow          : 0.13.0\\r\\npyxlsb           : none\\r\\ns3fs             : none\\r\\nscipy            : 1.3.0\\r\\nsqlalchemy       : 1.3.13\\r\\ntables           : 3.6.1\\r\\ntabulate         : none\\r\\nxarray           : none\\r\\nxlrd             : 2.0.1\\r\\nxlwt             : 1.3.0\\r\\nnumba            : none\\r </details>',\n",
       "   \" reproducible example ```python\\nwith pd.excelwriter('test.ods') as writer:\\r\\n    dataframe().to_excel(writer)\\n```  issue description raises `valueerror: max() arg is an empty sequence`  expected behavior write an empty sheet\",\n",
       "   'ref: https://github.com/pandas-dev/pandas/issues/43068#issuecomment-900504112\\r copying from the comment above:\\r > the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.excelwriter.html) of `excelwriter` says: \"none of the methods and properties are considered public.\".\\r it seems this line the documentation would be easy to miss, and it\\'d be better to make this more clear via the standard naming convention of a single leading underscore.',\n",
       "   'this works for openpyxl but it fails for xlsxwriter typeerror(\"nan/inf not supported in write_number()\")',\n",
       "   ' reproducible example ```python\\nimport pandas as pd\\r\\ntestbook = pd.excelwriter(\\r\\n    \"./test.xlsx\", engine=\"xlsxwriter\", engine_kwargs={\"nan_inf_to_errors\": true}\\r\\n)\\n```  issue description pandas documentation indicates to pass the options as a dictionary. as well as it spreading said values. \\r spreading confirmed [here](https://github.com/pandas-dev/pandas/blob/main/pandas/io/excel/_xlsxwriter.py#l216)\\r xlsxwriter [docs](https://xlsxwriter.readthedocs.io/workbook.html) indicate that they would like to receive the dictionary (unspread) as the secondary argument. \\r also:\\r\\ni do not get any runtime errors from this but, i get a linter message from pyright for abstractbaseclass\\r ```\\r\\n │   \\uf057  cannot instantiate abstract class \"excelwriter\" pyright (reportgeneraltypeissues) [10, 6]\\r\\n │      \\xa0\\xa0\"excelwriter.sheets\" is abstract \\r\\n │      \\xa0\\xa0\"excelwriter.book\" is abstract \\r\\n ```\\r presumably because of notimplementederror? i might have to re-raise this with pyright. let me know on that.  expected behavior directly pass the dictionary of arguments without spreading to xlsxwriter.',\n",
       "   ' reproducible example ```python\\ndf = pd.read_excel(self.file_path, sheet_name=self.sheet_name, header=none)\\n```  issue description use xlsxwriter to create an xlsx file that a user can fill out and re-upload.  however, if the user enter data or even if i just try to read the excel file without ever opening it in excel, it gives this error: \"colors must be argb hex values\".\\r i just pip installed the latest pandas to see if that corrected it and it did not.  expected behavior pandas can read xlsxwriter created file.',\n",
       "   '  - [x] i have checked that this issue has not already been reported. - [x] i have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas. - [ ] i have confirmed this bug exists on the master branch of pandas.  reproducible example ```python\\nimport pandas as pd\\r excel_path = r\"d:\\\\my_test.xlsm\"\\r\\nwith pd.excelwriter(excel_path, mode=\\'a\\') as writer:\\r\\n    # df.to_excel(writer, sheet_name=\\'sheet1\\')\\r\\n    pass\\r df_excel = pd.read_excel(excel_path, \\'sheet1\\')\\n```  issue description the specified excel file gets corrupted, despite the append mode. changing its extension to .xlsx can retrieve the raw data from it, but the macro is forever gone.\\r in my example i used _**with**_ and had only a _**pass**_ statement inside it, yet the file became useless.\\r [excel_macro_corruption.zip](https://github.com/pandas-dev/pandas/files/7706346/excel_macro_corruption.zip)\\r q1: can we know for sure that the default engine is used for .xlsm files?\\r\\nq2: should i contact openpyxl instead of you with this issue?  expected behavior as i\\'ve read since my first encounter of this bug, excelwriter doesn\\'t support macros, but a warning of some kind would be nice before wiping out a carefully written vba code from the excel file.',\n",
       "   \"fix for issue in the xlsxwriter engine where is adds a default\\n'general' format to cells if no other format is applied. this\\nisn't a bug, per se, but it prevents other row or column formatting. closes #9167\"]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ff222-7562-4e52-b737-4ec495f443e4",
   "metadata": {},
   "source": [
    "#### Copy the data/ directory to backend/\n",
    "\n",
    "Therefore, your backend directory should look something like\n",
    "\n",
    "```bash\n",
    "backend/\n",
    "|__ data/\n",
    "|__ src/\n",
    "|__ README.md\n",
    "|__ setup.py\n",
    "|__ pyproject.toml\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defect-search",
   "language": "python",
   "name": "defect-search"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

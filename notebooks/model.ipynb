{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be08a58-de10-4648-a19d-af3d5849557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c272aa3-7bab-49a4-92fc-4abbbf133c38",
   "metadata": {},
   "source": [
    "#### Create the ChromaDB Client and set the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c02b11-c978-4cb4-9ee5-41a87abf19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0e6aae-30dd-493e-af49-cfab618e8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMADB_PATH=\"/home/yikuang/workspace/defectsearch/notebooks/data/chromadb\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMADB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a80e21a-26e5-40dd-9396-d72dba86e1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['np2024-dataset']\n"
     ]
    }
   ],
   "source": [
    "print([entry.name for entry in chroma_client.list_collections()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fcd2c5d-3645-4885-8466-8d9f8dd4b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(\n",
    "    name = \"np2024-dataset\", \n",
    "    # embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"Huffon/sentence-klue-roberta-base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae5843-7d6d-45ed-98cd-cea7346697fc",
   "metadata": {},
   "source": [
    "#### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e18aea0-9a1d-4b1b-8f7c-2bc3a66e9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "files = glob(\"data/github-dataset/warehouse/*.csv\")\n",
    "dfs = [pd.read_csv(file) for file in files]\n",
    "df = dfs[3].dropna(subset = ['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15b99d2-f76e-4846-a59d-e5ee6deaebc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>node_id</th>\n",
       "      <th>title</th>\n",
       "      <th>state</th>\n",
       "      <th>labels</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>2428583885</td>\n",
       "      <td>sfc-gh-joshi</td>\n",
       "      <td>I_kwDOAA0YD86QwT_N</td>\n",
       "      <td>BUG: GroupBy.value_counts doesn't preserve ori...</td>\n",
       "      <td>open</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2024-07-24T22:41:33Z</td>\n",
       "      <td>2024-07-24T22:41:33Z</td>\n",
       "      <td>### Pandas version checks\\n\\n- [X] I have chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>2424738873</td>\n",
       "      <td>behrenhoff</td>\n",
       "      <td>I_kwDOAA0YD86QhpQ5</td>\n",
       "      <td>BUG: Error message in read_csv misleading when...</td>\n",
       "      <td>open</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2024-07-23T09:39:47Z</td>\n",
       "      <td>2024-07-24T21:36:58Z</td>\n",
       "      <td>### Pandas version checks\\r\\n\\r\\n- [X] I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>2423712812</td>\n",
       "      <td>flownt</td>\n",
       "      <td>I_kwDOAA0YD86Qduws</td>\n",
       "      <td>BUG: pandas.to_datetime reports incorrect inde...</td>\n",
       "      <td>open</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2024-07-22T20:26:26Z</td>\n",
       "      <td>2024-07-24T21:44:03Z</td>\n",
       "      <td>### Pandas version checks\\n\\n- [X] I have chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>2421504459</td>\n",
       "      <td>aram-cinnamon</td>\n",
       "      <td>PR_kwDOAA0YD852BM9q</td>\n",
       "      <td>BUG: `query` on columns with characters like #...</td>\n",
       "      <td>open</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2024-07-21T16:08:46Z</td>\n",
       "      <td>2024-07-23T21:01:33Z</td>\n",
       "      <td>- [x] closes #59285\\r\\n- [x] [Tests added and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>2421257349</td>\n",
       "      <td>Jonathan-Wei</td>\n",
       "      <td>I_kwDOAA0YD86QUXSF</td>\n",
       "      <td>BUG: Couldn't run sql:  'Connection' object ha...</td>\n",
       "      <td>open</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2024-07-21T06:53:08Z</td>\n",
       "      <td>2024-07-21T13:35:21Z</td>\n",
       "      <td>### Pandas version checks\\n\\n- [X] I have chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>1239398</td>\n",
       "      <td>wesm</td>\n",
       "      <td>MDU6SXNzdWUxMjM5Mzk4</td>\n",
       "      <td>DataFrame.__ne__ not implemented</td>\n",
       "      <td>closed</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2011-07-18T02:15:11Z</td>\n",
       "      <td>2011-07-20T19:46:26Z</td>\n",
       "      <td>See\\n\\n```\\ndm = DataFrame({'col1':[1,2],'col2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11680</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>997165</td>\n",
       "      <td>wesm</td>\n",
       "      <td>MDU6SXNzdWU5OTcxNjU=</td>\n",
       "      <td>\"Proper\" boolean array with NA handling in Dat...</td>\n",
       "      <td>closed</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2011-06-03T09:08:28Z</td>\n",
       "      <td>2011-06-14T14:06:41Z</td>\n",
       "      <td>Currently booleans are getting casted to float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>934142</td>\n",
       "      <td>surbas</td>\n",
       "      <td>MDU6SXNzdWU5MzQxNDI=</td>\n",
       "      <td>Importing data using HDFStore with pre-epoch d...</td>\n",
       "      <td>closed</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2011-05-20T22:13:31Z</td>\n",
       "      <td>2011-06-23T04:17:27Z</td>\n",
       "      <td>I have data with a DataFrame that goes back to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11682</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>358952</td>\n",
       "      <td>wesm</td>\n",
       "      <td>MDU6SXNzdWUzNTg5NTI=</td>\n",
       "      <td>weights option may not be working in pandas.st...</td>\n",
       "      <td>closed</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2010-10-12T16:15:10Z</td>\n",
       "      <td>2011-12-31T16:53:33Z</td>\n",
       "      <td>Need to investigate (user notified)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11683</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>339355</td>\n",
       "      <td>andylei</td>\n",
       "      <td>MDU6SXNzdWUzMzkzNTU=</td>\n",
       "      <td>np.fix doesn't work</td>\n",
       "      <td>closed</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2010-09-29T19:45:47Z</td>\n",
       "      <td>2014-02-11T20:40:01Z</td>\n",
       "      <td>```\\nIn [28]: np.fix(Series([1,2,3], range(3))...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11684 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1      https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2      https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3      https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4      https://api.github.com/repos/pandas-dev/pandas...   \n",
       "...                                                  ...   \n",
       "11679  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "11680  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "11681  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "11682  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "11683  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                       repository_url          id  \\\n",
       "0      https://api.github.com/repos/pandas-dev/pandas  2428583885   \n",
       "1      https://api.github.com/repos/pandas-dev/pandas  2424738873   \n",
       "2      https://api.github.com/repos/pandas-dev/pandas  2423712812   \n",
       "3      https://api.github.com/repos/pandas-dev/pandas  2421504459   \n",
       "4      https://api.github.com/repos/pandas-dev/pandas  2421257349   \n",
       "...                                               ...         ...   \n",
       "11679  https://api.github.com/repos/pandas-dev/pandas     1239398   \n",
       "11680  https://api.github.com/repos/pandas-dev/pandas      997165   \n",
       "11681  https://api.github.com/repos/pandas-dev/pandas      934142   \n",
       "11682  https://api.github.com/repos/pandas-dev/pandas      358952   \n",
       "11683  https://api.github.com/repos/pandas-dev/pandas      339355   \n",
       "\n",
       "                user               node_id  \\\n",
       "0       sfc-gh-joshi    I_kwDOAA0YD86QwT_N   \n",
       "1         behrenhoff    I_kwDOAA0YD86QhpQ5   \n",
       "2             flownt    I_kwDOAA0YD86Qduws   \n",
       "3      aram-cinnamon   PR_kwDOAA0YD852BM9q   \n",
       "4       Jonathan-Wei    I_kwDOAA0YD86QUXSF   \n",
       "...              ...                   ...   \n",
       "11679           wesm  MDU6SXNzdWUxMjM5Mzk4   \n",
       "11680           wesm  MDU6SXNzdWU5OTcxNjU=   \n",
       "11681         surbas  MDU6SXNzdWU5MzQxNDI=   \n",
       "11682           wesm  MDU6SXNzdWUzNTg5NTI=   \n",
       "11683        andylei  MDU6SXNzdWUzMzkzNTU=   \n",
       "\n",
       "                                                   title   state labels  \\\n",
       "0      BUG: GroupBy.value_counts doesn't preserve ori...    open    Bug   \n",
       "1      BUG: Error message in read_csv misleading when...    open    Bug   \n",
       "2      BUG: pandas.to_datetime reports incorrect inde...    open    Bug   \n",
       "3      BUG: `query` on columns with characters like #...    open    Bug   \n",
       "4      BUG: Couldn't run sql:  'Connection' object ha...    open    Bug   \n",
       "...                                                  ...     ...    ...   \n",
       "11679                   DataFrame.__ne__ not implemented  closed    Bug   \n",
       "11680  \"Proper\" boolean array with NA handling in Dat...  closed    Bug   \n",
       "11681  Importing data using HDFStore with pre-epoch d...  closed    Bug   \n",
       "11682  weights option may not be working in pandas.st...  closed    Bug   \n",
       "11683                                np.fix doesn't work  closed    Bug   \n",
       "\n",
       "                 created_at            updated_at  \\\n",
       "0      2024-07-24T22:41:33Z  2024-07-24T22:41:33Z   \n",
       "1      2024-07-23T09:39:47Z  2024-07-24T21:36:58Z   \n",
       "2      2024-07-22T20:26:26Z  2024-07-24T21:44:03Z   \n",
       "3      2024-07-21T16:08:46Z  2024-07-23T21:01:33Z   \n",
       "4      2024-07-21T06:53:08Z  2024-07-21T13:35:21Z   \n",
       "...                     ...                   ...   \n",
       "11679  2011-07-18T02:15:11Z  2011-07-20T19:46:26Z   \n",
       "11680  2011-06-03T09:08:28Z  2011-06-14T14:06:41Z   \n",
       "11681  2011-05-20T22:13:31Z  2011-06-23T04:17:27Z   \n",
       "11682  2010-10-12T16:15:10Z  2011-12-31T16:53:33Z   \n",
       "11683  2010-09-29T19:45:47Z  2014-02-11T20:40:01Z   \n",
       "\n",
       "                                                    body  \n",
       "0      ### Pandas version checks\\n\\n- [X] I have chec...  \n",
       "1      ### Pandas version checks\\r\\n\\r\\n- [X] I have ...  \n",
       "2      ### Pandas version checks\\n\\n- [X] I have chec...  \n",
       "3      - [x] closes #59285\\r\\n- [x] [Tests added and ...  \n",
       "4      ### Pandas version checks\\n\\n- [X] I have chec...  \n",
       "...                                                  ...  \n",
       "11679  See\\n\\n```\\ndm = DataFrame({'col1':[1,2],'col2...  \n",
       "11680  Currently booleans are getting casted to float...  \n",
       "11681  I have data with a DataFrame that goes back to...  \n",
       "11682              Need to investigate (user notified)\\n  \n",
       "11683  ```\\nIn [28]: np.fix(Series([1,2,3], range(3))...  \n",
       "\n",
       "[11684 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f79ca-5c64-47eb-b01b-d67396fc2a53",
   "metadata": {},
   "source": [
    "#### Clean the data uploaded to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1ed142-6b50-49c8-b724-1dba3f9af289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str):\n",
    "    pattern = re.compile(r'### Pandas version checks.*?### Reproducible Example', re.DOTALL)\n",
    "    # Replace the matched section with '### Reproducible Example'\n",
    "    cleaned_text = re.sub(pattern, '### Reproducible Example', text)\n",
    "    # Regex to match the ### Installed Versions section and its content\n",
    "    pattern = re.compile(r'### Installed Versions.*?(</details>|$)', re.DOTALL)\n",
    "    # Replace the matched section with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip().lower().replace(\"###\", \"\")\n",
    "    cleaned_text = re.sub(r'\\n\\s*\\n+', ' ', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ba1fe3-b907-42ec-bc9a-018e85b86223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_388269/1253343363.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_body'] = df['body'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_body'] = df['body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc465050-00fa-4e22-899d-7ffd30e694e4",
   "metadata": {},
   "source": [
    "#### Upload the data to ChromaDB"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eaad2789-a340-4272-8fd2-816e883d5dae",
   "metadata": {},
   "source": [
    "import uuid\n",
    "from tqdm import tqdm\n",
    "\n",
    "i, chunk_size = 0, 1_000\n",
    "\n",
    "for row in df.itertuples():\n",
    "    # Insert the embedded sentences into the database on every chunk_size chunk\n",
    "    if i % chunk_size == 0 and i != 0:        \n",
    "        chunk_df = df.iloc[i - chunk_size: i]\n",
    "        collection.upsert(\n",
    "            documents = chunk_df[\"body\"].to_list(), \n",
    "            ids = chunk_df[\"node_id\"].to_list()\n",
    "        )\n",
    "    i += 1\n",
    "    \n",
    "collection.upsert(\n",
    "    documents = df.iloc[i - chunk_size:]['body'].to_list(), \n",
    "    ids = df.iloc[i - chunk_size:][\"node_id\"].to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45dbe08f-959c-483b-a353-efadfb956c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"pd.ExcelWriter cannot accept an io.BytesIO instance as first arg\"\n",
    "results = collection.query(query_texts=[query], n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c83da1-2580-44c7-b570-4b6d04332532",
   "metadata": {},
   "source": [
    "#### Import the Pretrained LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02bb7f80-8d31-4475-be17-22f210d31cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yikuang/miniconda3/envs/rapids-defectsearch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  2.00it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import numpy as np\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b76f791a-cacd-4633-a93b-09fc0c01813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def craft_prompt(query: str, df: pd.DataFrame, chroma_collection, min_ref_docs: int = 2, distance_threshold = 0.1) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    min_ref_docs : minimum number of documents we want the RAG model to reference.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = chroma_collection.query(\n",
    "        query_texts = [query],  # Chroma will embed this for you\n",
    "        n_results = 10,  # How many results to return\n",
    "    )\n",
    "\n",
    "    reference_ids: List[str] = results['ids'][0]\n",
    "    filtered_result = df[df.node_id.isin(reference_ids)]\n",
    "\n",
    "    # Get values that deviate less than 0.1 distance away\n",
    "    documents = np.array(filtered_result['cleaned_body'].to_list())\n",
    "    distances = np.array(results[\"distances\"][0])\n",
    "\n",
    "    distance_ids = {k: v for k,v in zip(reference_ids, distances)}\n",
    "    \n",
    "    relevant_documents = documents[distances < min(distances) + distance_threshold]\n",
    "\n",
    "    if len(relevant_documents) < min_ref_docs:\n",
    "        relevant_documents = documents[:min_ref_docs]\n",
    "    \n",
    "    if len(relevant_documents) == 0:\n",
    "        relevant_documents = documents[:1]  # At least take the top result if none within the threshold\n",
    "\n",
    "    # Join results with new lines for the context\n",
    "    context = \"\\n\".join(relevant_documents) \n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant that answers questions from a database of GitHub issues.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Answer the following question using only the provided context. Do not assume or add information beyond what is in the context. \\n\"\n",
    "                \"If the context does not contain sufficient information to answer the question, explicitly state that the context is insufficient and provide your own suggestions with a clear warning. \\n\"\n",
    "                \"The context are entries in a database, so your answer should say instead that you had referenced the database. \\n\"\n",
    "                \"Context:\\n\"\n",
    "                \"{context}\\n\\n\"\n",
    "                \"Question: {query}\\n\\n\"\n",
    "                \"Here are the entries in the database that might be relevant to your query:\\n\"\n",
    "                \"{entries}\"\n",
    "            ).format(context=context, query=query, entries=\"\".join([f'- {entry}\\n' for entry in relevant_documents]))\n",
    "        }\n",
    "    ], distance_ids\n",
    "\n",
    "def search_term(query, pipe, df, chroma_collection):\n",
    "\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": 500,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 0.0,\n",
    "        \"do_sample\": False,\n",
    "    }\n",
    "\n",
    "    prompt, reference_ids = craft_prompt(query, df, chroma_collection)\n",
    "    output = pipe(prompt, **generation_args)\n",
    "    \n",
    "    return output, reference_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4740878a-7823-49e0-b0a1-e156f6741d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Ensure 'collection' is properly initialized and configured\n",
    "result, reference_ids = search_term(\n",
    "    \"test\",\n",
    "    pipe, \n",
    "    df, \n",
    "    chroma_collection = collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "685ac56e-8a33-44b8-b93e-e562afe0dd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' The context provided does not contain sufficient information to answer the question about the variable number of tests in `test_binops` failing with empty `.attrs` on Ubuntu 18. The context only mentions this issue without providing specific details or a solution. To answer this question, I would need to reference the database for more information on this issue.'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f2cd79d-f9ba-404c-8636-013444b3efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The context provided does not contain sufficient information to answer the question about the variable number of tests in `test_binops` failing with empty `.attrs` on Ubuntu 18. The context only mentions this issue without providing specific details or a solution. To answer this question, I would need to reference the database for more information on this issue.\n"
     ]
    }
   ],
   "source": [
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72254cab-ed3b-4ecc-a8ab-ef6b3ded0e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Memory leak with .rolling().max() in pandas 0.24.2 '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.node_id == \"MDU6SXNzdWU0MjYwMTc3MjQ=\"].title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "189ca4b4-5283-4430-a3a5-5bc61fa2295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MDExOlB1bGxSZXF1ZXN0MjAwNTUyNDE5': 1.1448930501937866,\n",
       " 'MDExOlB1bGxSZXF1ZXN0NTk2NzA4ODY=': 1.163944959640503,\n",
       " 'MDExOlB1bGxSZXF1ZXN0MTMzOTMyNTU=': 1.1797651052474976,\n",
       " 'MDExOlB1bGxSZXF1ZXN0MjM3NDE2NzE=': 1.2089669704437256,\n",
       " 'PR_kwDOAA0YD84wZZ_3': 1.2155227661132812,\n",
       " 'MDExOlB1bGxSZXF1ZXN0NzIzMzE0MjI0': 1.2461981773376465,\n",
       " 'MDExOlB1bGxSZXF1ZXN0MTkyNDM4NTY=': 1.2664517164230347,\n",
       " 'PR_kwDOAA0YD84zGyJw': 1.269770622253418,\n",
       " 'MDExOlB1bGxSZXF1ZXN0MjA1ODA3MzI0': 1.287787675857544,\n",
       " 'MDU6SXNzdWU2MjQ1MDgzMTQ=': 1.298712968826294}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2e770-7e11-4106-9bc8-20636912587c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe8192-b42d-4472-b29b-656a6b4a7460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aea29d-5891-45c1-a631-df2294b6dadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db4ade-f989-4fcf-89e8-e884adc22707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d071f7-5eb9-4395-bf50-908db8fd7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"groupby value count doesnt preserve my order when i added in the sort argument\"\n",
    "\n",
    "results = search_term(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda1bd4-9a15-4e10-9017-5021c793bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[-1]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306a5ad-c526-4347-81b0-c8c6981c06ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-defectsearch",
   "language": "python",
   "name": "rapids-defectsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
